{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio_client paddleocr paddlepaddle deepface transformers TTS openai-whisper pyngrok fastapi[all] nest_asyncio -q\n",
        "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok\n",
        "!ngrok authtoken 2NqtkyBMF0KF99ofEU1fGz1pCJS_3XehxpoU47JGBiqY6tV7M\n",
        "!sudo apt update && sudo apt upgrade && sudo apt install ffmpeg\n",
        "!pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
      ],
      "metadata": {
        "id": "i-I8PKyUIZh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f19be9c-2d50-4405-d6b4-80cbddf30cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb https://ngrok-agent.s3.amazonaws.com buster main\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [495 kB]\n",
            "Hit:5 https://ngrok-agent.s3.amazonaws.com buster InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 497 kB in 2s (234 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ngrok is already the newest version (3.3.4).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  linux-headers-5.15.0-82 linux-headers-5.15.0-82-generic\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://ngrok-agent.s3.amazonaws.com buster InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  linux-headers-5.15.0-82 linux-headers-5.15.0-82-generic\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  linux-headers-5.15.0-82 linux-headers-5.15.0-82-generic\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynIQOpICITpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408f4055-a98a-4ba1-bcb8-cf814e2c6c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:24<00:00, 127MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException, Body\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uuid\n",
        "import os\n",
        "import uvicorn\n",
        "import torch\n",
        "from TTS.api import TTS\n",
        "from fastapi.responses import FileResponse\n",
        "import asyncio\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from deepface import DeepFace\n",
        "import paddleocr\n",
        "from gradio_client import Client\n",
        "\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "\n",
        "client = Client(\"https://huggingfaceh4-falcon-chat.hf.space/\", serialize=False)\n",
        "ocr_reader = paddleocr.PaddleOCR(lang=\"hi\")\n",
        "voice_model = whisper.load_model(\"large-v2\").to(device)\n",
        "tts = TTS('tts_models/en/jenny/jenny').to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")\n",
        "quantized_ner_model = torch.ao.quantization.quantize_dynamic(model,{torch.nn.Linear},dtype=torch.qint8)\n",
        "del model\n",
        "port=8888\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI(title=\"SIH 2023 Backend\")\n",
        "\n",
        "app.add_middleware(\n",
        "CORSMiddleware,\n",
        "allow_origins=[\"*\"],\n",
        "allow_credentials=True,\n",
        "allow_methods=[\"*\"],\n",
        "allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class TTSNER(BaseModel):\n",
        "    text: str\n",
        "    emotion: str = \"Cheerful & Professional\"\n",
        "\n",
        "class FaceResponse(BaseModel):\n",
        "    prediction: bool\n",
        "\n",
        "class FaceDetect(BaseModel):\n",
        "    prediction: str\n",
        "\n",
        "def remove(known_image_path,test_image_path):\n",
        "    os.remove(known_image_path)\n",
        "    os.remove(test_image_path)\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def home():\n",
        "    return \"SIH - LICHT DEN CODE\"\n",
        "\n",
        "@app.post(\"/face-detect/\")\n",
        "async def face_detect(img: UploadFile = File(...)):\n",
        "    img_path = f\"{uuid.uuid4()}.jpg\"\n",
        "    with open(img_path, \"wb\") as known_image_file:\n",
        "        known_image_file.write(img.file.read())\n",
        "    result = DeepFace.extract_faces(img_path,enforce_detection=False)[0].get('confidence')\n",
        "    os.remove(img_path)\n",
        "    if result>5:\n",
        "        return FaceDetect(prediction=\"Done!!!\")\n",
        "    else:\n",
        "        return FaceDetect(prediction=\"Face could not be detected. Please confirm that the picture is a face photo.\")\n",
        "\n",
        "@app.post(\"/face-match/\")\n",
        "async def face_match(known_face: UploadFile = File(...), test_face: UploadFile = File(...)):\n",
        "    try:\n",
        "        known_image_path = f\"{uuid.uuid4()}.jpg\"\n",
        "        test_image_path = f\"{uuid.uuid4()}.jpg\"\n",
        "        with open(known_image_path, \"wb\") as known_image_file:\n",
        "            known_image_file.write(known_face.file.read())\n",
        "        with open(test_image_path, \"wb\") as test_image_file:\n",
        "            test_image_file.write(test_face.file.read())\n",
        "        result = DeepFace.verify(known_image_path, test_image_path, model_name='Facenet512', distance_metric='euclidean_l2').get('verified')\n",
        "        remove(known_image_path,test_image_path)\n",
        "        return FaceResponse(prediction=result)\n",
        "\n",
        "    except Exception as e:\n",
        "        remove(known_image_path,test_image_path)\n",
        "        if str(e)=='''Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.''':\n",
        "            raise HTTPException(status_code=399, detail=\"Face could not be detected. Please confirm that the picture is a face photo.\")\n",
        "        else:\n",
        "            raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/transcribe/\")\n",
        "async def transcribe_audio(file: UploadFile = File(...)):\n",
        "    audio_path = f\"{uuid.uuid4()}.webm\"\n",
        "    with open(audio_path, \"wb\") as f:\n",
        "        f.write(await file.read())\n",
        "    result = voice_model.transcribe(whisper.pad_or_trim(whisper.load_audio(audio_path)))[\"text\"]\n",
        "    os.remove(audio_path)\n",
        "    return {\"text\": result}\n",
        "\n",
        "@app.post(\"/ocr/\")\n",
        "async def OCR(file: UploadFile = File(...)):\n",
        "    pic_path = f\"{uuid.uuid4()}.jpg\"\n",
        "    with open(pic_path, \"wb\") as f:\n",
        "        f.write(await file.read())\n",
        "    result = ' '.join([word[1][0] for line in ocr_reader.ocr(pic_path) for word in line])\n",
        "    os.remove(pic_path)\n",
        "    return {\"text\": result}\n",
        "\n",
        "@app.post(\"/ner/\")\n",
        "async def get_ner_endpoint(request: TTSNER = Body(...)):\n",
        "    sentence = request.text.strip()\n",
        "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        logits = quantized_ner_model(**tok_sentence).logits.argmax(-1)\n",
        "        predicted_tokens_classes = [\n",
        "            quantized_ner_model.config.id2label[t.item()] for t in logits[0]]\n",
        "\n",
        "        predicted_labels = []\n",
        "\n",
        "        previous_token_id = 0\n",
        "        word_ids = tok_sentence.word_ids()\n",
        "        for word_index in range(len(word_ids)):\n",
        "            if word_ids[word_index] == None:\n",
        "                previous_token_id = word_ids[word_index]\n",
        "            elif word_ids[word_index] == previous_token_id:\n",
        "                previous_token_id = word_ids[word_index]\n",
        "            else:\n",
        "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
        "                previous_token_id = word_ids[word_index]\n",
        "\n",
        "    return {\"LOC\": [word for word, label in zip(sentence.split(' '), predicted_labels) if \"LOC\" in label]}\n",
        "\n",
        "@app.post(\"/coqui-tts/\")\n",
        "async def coqui_tts(request: TTSNER = Body(...)):\n",
        "    out = f\"{uuid.uuid4()}.ogg\"\n",
        "    async def remove():\n",
        "        loop = asyncio.get_event_loop()\n",
        "        await loop.run_in_executor(None, lambda: os.remove(out))\n",
        "    tts.tts_to_file(request.text, file_path=out, emotion=request.emotion)\n",
        "    return FileResponse(out,headers={\"Content-Disposition\":f\"attachment; filename={out}\"},background=remove)\n",
        "\n",
        "@app.post(\"/chat/\")\n",
        "async def falcon(request: TTSNER = Body(...)):\n",
        "  result = client.predict(\n",
        "  request.text, # str in 'Type an input and press Enter' Textbox component\n",
        "  \"\", # str (filepath to JSON file) in 'parameter_9' Chatbot component\n",
        "  \"The following is a conversation between a highly knowledgeable and intelligent AI assistant, called Falcon, and a human user, called User. In the following interactions, User and Falcon will converse in natural language, and Falcon will answer User's questions. Falcon was built to be respectful, polite and inclusive. Falcon was built by the Technology Innovation Institute in Abu Dhabi. Falcon will never decline to answer a question, and always attempts to give an answer that User would be satisfied with. It knows a lot, and always tells the truth. The conversation begins.\", # str in 'Instructions' Textbox component\n",
        "  0.7, # int | float (numeric value between 0.1 and 2.0) in 'Temperature' Slider component\n",
        "  0.8, # int | float (numeric value between 0.1 and 0.99) in 'p (nucleus sampling)' Slider component\n",
        "  fn_index=1)[0][1]\n",
        "  return {\"text\":result}\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    ngrok_tunnel = ngrok.connect(port)\n",
        "    print('Public URL:', ngrok_tunnel.public_url)\n",
        "    nest_asyncio.apply()\n",
        "    uvicorn.run(app,port=port)"
      ],
      "metadata": {
        "id": "DtnjO2BFCdhF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
